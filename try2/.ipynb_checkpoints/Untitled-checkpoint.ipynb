{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a94a7e1a-1004-4100-b777-587441b3a2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFaceEndpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9671a3-84af-4b73-b552-4ade91b42aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from getpass import getpass\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d381facb-bca4-48fb-921e-87c1dcca4033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "753f663b-2d5c-4582-8da0-625b3e3721c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d72b0447-fdd8-4df1-b373-c4fbcfa9dc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14368f83-1be0-4ba5-b173-a810bec0fc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# question = \"Who won the FIFA World Cup in the year 1994? \"\n",
    "\n",
    "# template = \"\"\"Question: {question}\n",
    "\n",
    "# Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "# prompt = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "680a9f24-7b0e-4ad7-85fe-b2f056c6426d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING! max_length is not default parameter.\n",
      "                    max_length was transferred to model_kwargs.\n",
      "                    Please make sure that max_length is what you intended.\n",
      "WARNING! token is not default parameter.\n",
      "                    token was transferred to model_kwargs.\n",
      "                    Please make sure that token is what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to C:\\Users\\Devangana\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 0.3.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n",
      "C:\\Python312\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The FIFA World Cup is an international football competition. It is held every four years. The year 1994 is indeed a year that saw the FIFA World Cup being held. So, to find out which team won the FIFA World Cup in the year 1994, we need to look up the history of the FIFA World Cup tournaments.\n",
      "\n",
      "The 1994 FIFA World Cup was held in the United States from June 17 to July 17, 1994. The final match was held on July 17, 1994, between Brazil and Italy. Brazil won the match 0-0 (after extra time) and 3-2 in a penalty shootout.\n",
      "\n",
      "Therefore, the answer to the question is Brazil. They won the FIFA World Cup in the year 1994.\n"
     ]
    }
   ],
   "source": [
    "repo_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=repo_id, max_length=500, temperature=0.5, token=HUGGINGFACEHUB_API_TOKEN\n",
    ")\n",
    "# llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "# print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d93dca5-751e-4352-a928-248cbc8e972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a6bb33d-24ee-482b-bdb5-e0048234d672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='CODING CONTEST\\nNOMURA INDIA\\nINFORMATION TECHNOLOGY DIVISION  \\n', metadata={'source': 'KakushIN_problem_statement.pdf', 'page': 0}), Document(page_content='1 Diversity Hires Forecasting \\nProblem Statement : \\nAlwaysFirst IT Enabled services has been struggling with diversity candidate ratio in their firm . \\nCurrently AlwaysFirst stands at a men to women ratio of 73:27 . While they are working on ways to \\nhire more gender diverse talent, it has not picked the right momentum due to lack of supporting \\ndata. AlwaysFirst is now looking at an intelligent way to create and analyse the data to improve \\ntheir diversity ratio.  \\nSolutions:  \\nBuildTogether: A dashboard of D&I metrics to ensure managers can stay accountable for \\nreaching corporate D&I goals  \\nKey Features \\n1.Reviewing the historic data to identify clear trends or patterns\\na.Identify the diversity in applicants for a position\\nb. Identify  hiring ratios at every stage of hiring\\nc.Introduce new vendors for laterals\\nd.Introduce new campuses for early careers\\ne.Vendor graph depicting trend on positions filled with diverse candidates.\\n2.Demand Prediction based on historic data\\na.Band based demand prediction to meet minimum diversity ratios targets set by t he\\nDiv\\nisions\\nb.BU based demand prediction\\n3.Data Analysis â€“ slice and dice of data\\na.Ratio across all levels (Analyst, Associate, VP, ED, MD)\\n4.Real time tracking of diversity ratios\\na.To be able to view/ use custom dataset provided by HR\\nb.To be able to add candidate data to existing dataset\\n5.Provide Graphical representation of Band- wise and BU -wise rise/fall in demand and supply\\n6.Highlighting diversity  ratio gaps on the BU map.\\n7.Adjust how you screen or search for candidates (80% is through referrals/network )', metadata={'source': 'KakushIN_problem_statement.pdf', 'page': 1}), Document(page_content='2 Users fo\\nr the solution (this is not an exhaustive list)  \\n1.Business Units  Heads\\n2.Business Units  HRA team\\n3.CIO\\n4.Recruitment team\\n5.D&I Team', metadata={'source': 'KakushIN_problem_statement.pdf', 'page': 2})]\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"KakushIN_problem_statement.pdf\")\n",
    "data = loader.load()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3838adcf-c9d8-413b-9743-00afc3dae437",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=20)\n",
    "\n",
    "text_chunks = text_splitter.split_documents(data)\n",
    "\n",
    "len(text_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44bcd805-d6ca-44b2-bae1-dd25a624c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_store = FAISS.from_documents(text_chunks, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5bd0298b-0efa-44f2-b2af-fb48a1878e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer: Let's think step by step.\"\"\"\n",
    "system_prompt = (\n",
    "    \"Use the given context to answer the question. \"\n",
    "    \"If you don't know the answer, say you don't know. \"\n",
    "    \"Use three sentence maximum and keep the answer concise. \"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51ba2ffb-49f4-4056-bcae-82a9977efeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"what is the problem statement about?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80488eb5-65a7-4c2e-be30-b04e5922b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vector_store.as_retriever(search_kwargs={\"k\": 2}))\n",
    "result = qa.invoke(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
